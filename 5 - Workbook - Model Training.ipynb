{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Regularized Regression algos\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "# Import Tree Ensemble algos\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load ABT from Module 3\n",
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "\n",
    "# Create separate object for input features\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434228</td>\n",
       "      <td>2.579195</td>\n",
       "      <td>2322.785235</td>\n",
       "      <td>12746.659732</td>\n",
       "      <td>0.878523</td>\n",
       "      <td>39.495973</td>\n",
       "      <td>4.388591</td>\n",
       "      <td>5.004698</td>\n",
       "      <td>5.185906</td>\n",
       "      <td>39.561074</td>\n",
       "      <td>3.361745</td>\n",
       "      <td>22.909396</td>\n",
       "      <td>15.770470</td>\n",
       "      <td>38.508725</td>\n",
       "      <td>69.471141</td>\n",
       "      <td>65.012752</td>\n",
       "      <td>464.265772</td>\n",
       "      <td>139.610067</td>\n",
       "      <td>6.510067</td>\n",
       "      <td>2.779195</td>\n",
       "      <td>0.092617</td>\n",
       "      <td>24.343624</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>17.940268</td>\n",
       "      <td>0.359732</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.059060</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.119463</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.073154</td>\n",
       "      <td>0.643624</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>0.580537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.072914</td>\n",
       "      <td>0.930476</td>\n",
       "      <td>1297.101677</td>\n",
       "      <td>34805.545024</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>46.985862</td>\n",
       "      <td>4.498340</td>\n",
       "      <td>8.441995</td>\n",
       "      <td>7.442707</td>\n",
       "      <td>52.334853</td>\n",
       "      <td>4.693709</td>\n",
       "      <td>25.724463</td>\n",
       "      <td>17.999282</td>\n",
       "      <td>6.615223</td>\n",
       "      <td>19.865080</td>\n",
       "      <td>17.092542</td>\n",
       "      <td>227.249819</td>\n",
       "      <td>71.510905</td>\n",
       "      <td>1.975224</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>0.289993</td>\n",
       "      <td>21.209025</td>\n",
       "      <td>0.441892</td>\n",
       "      <td>6.452059</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.153601</td>\n",
       "      <td>0.235817</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.324442</td>\n",
       "      <td>0.190252</td>\n",
       "      <td>0.443305</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.260477</td>\n",
       "      <td>0.479089</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.180146</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.493637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1351.000000</td>\n",
       "      <td>1542.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1913.500000</td>\n",
       "      <td>6183.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3014.750000</td>\n",
       "      <td>11761.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7842.000000</td>\n",
       "      <td>436471.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4508.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              beds        baths         sqft       lot_size     basement  \\\n",
       "count  1490.000000  1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      3.434228     2.579195  2322.785235   12746.659732     0.878523   \n",
       "std       1.072914     0.930476  1297.101677   34805.545024     0.326790   \n",
       "min       1.000000     1.000000   500.000000       0.000000     0.000000   \n",
       "25%       3.000000     2.000000  1351.000000    1542.000000     1.000000   \n",
       "50%       4.000000     3.000000  1913.500000    6183.000000     1.000000   \n",
       "75%       4.000000     3.000000  3014.750000   11761.000000     1.000000   \n",
       "max       5.000000     6.000000  7842.000000  436471.000000     1.000000   \n",
       "\n",
       "       restaurants    groceries    nightlife        cafes     shopping  \\\n",
       "count  1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean     39.495973     4.388591     5.004698     5.185906    39.561074   \n",
       "std      46.985862     4.498340     8.441995     7.442707    52.334853   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       6.000000     1.000000     0.000000     0.000000     6.000000   \n",
       "50%      21.000000     3.000000     2.000000     3.000000    20.000000   \n",
       "75%      56.000000     7.000000     6.000000     6.000000    50.000000   \n",
       "max     266.000000    24.000000    53.000000    47.000000   340.000000   \n",
       "\n",
       "       arts_entertainment  beauty_spas  active_life   median_age      married  \\\n",
       "count         1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean             3.361745    22.909396    15.770470    38.508725    69.471141   \n",
       "std              4.693709    25.724463    17.999282     6.615223    19.865080   \n",
       "min              0.000000     0.000000     0.000000    22.000000    11.000000   \n",
       "25%              0.000000     4.000000     4.000000    33.000000    59.000000   \n",
       "50%              2.000000    15.000000    10.000000    38.000000    74.000000   \n",
       "75%              5.000000    35.000000    21.000000    43.000000    84.000000   \n",
       "max             35.000000   177.000000    94.000000    69.000000   100.000000   \n",
       "\n",
       "       college_grad  property_tax    insurance  median_school  num_schools  \\\n",
       "count   1490.000000   1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      65.012752    464.265772   139.610067       6.510067     2.779195   \n",
       "std       17.092542    227.249819    71.510905       1.975224     0.517235   \n",
       "min        5.000000     88.000000    30.000000       1.000000     1.000000   \n",
       "25%       53.250000    321.000000    94.000000       5.000000     3.000000   \n",
       "50%       66.000000    426.000000   125.000000       7.000000     3.000000   \n",
       "75%       78.000000    572.000000   169.000000       8.000000     3.000000   \n",
       "max      100.000000   4508.000000  1374.000000      10.000000     4.000000   \n",
       "\n",
       "       two_and_two  property_age  during_recession  school_score  \\\n",
       "count  1490.000000   1490.000000       1490.000000   1490.000000   \n",
       "mean      0.092617     24.343624          0.265772     17.940268   \n",
       "std       0.289993     21.209025          0.441892      6.452059   \n",
       "min       0.000000      0.000000          0.000000      3.000000   \n",
       "25%       0.000000      6.000000          0.000000     12.000000   \n",
       "50%       0.000000     20.000000          0.000000     18.000000   \n",
       "75%       0.000000     38.000000          1.000000     24.000000   \n",
       "max       1.000000    114.000000          1.000000     30.000000   \n",
       "\n",
       "       exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "count           1490.000000                  1490.000000   \n",
       "mean               0.359732                     0.024161   \n",
       "std                0.480083                     0.153601   \n",
       "min                0.000000                     0.000000   \n",
       "25%                0.000000                     0.000000   \n",
       "50%                0.000000                     0.000000   \n",
       "75%                1.000000                     0.000000   \n",
       "max                1.000000                     1.000000   \n",
       "\n",
       "       exterior_walls_Combination  exterior_walls_Metal  \\\n",
       "count                 1490.000000           1490.000000   \n",
       "mean                     0.059060              0.065772   \n",
       "std                      0.235817              0.247966   \n",
       "min                      0.000000              0.000000   \n",
       "25%                      0.000000              0.000000   \n",
       "50%                      0.000000              0.000000   \n",
       "75%                      0.000000              0.000000   \n",
       "max                      1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count             1490.000000           1490.000000   \n",
       "mean                 0.119463              0.037584   \n",
       "std                  0.324442              0.190252   \n",
       "min                  0.000000              0.000000   \n",
       "25%                  0.000000              0.000000   \n",
       "50%                  0.000000              0.000000   \n",
       "75%                  0.000000              0.000000   \n",
       "max                  1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                         1490.000000          1490.000000   1490.000000   \n",
       "mean                             0.268456             0.065772      0.073154   \n",
       "std                              0.443305             0.247966      0.260477   \n",
       "min                              0.000000             0.000000      0.000000   \n",
       "25%                              0.000000             0.000000      0.000000   \n",
       "50%                              0.000000             0.000000      0.000000   \n",
       "75%                              1.000000             0.000000      0.000000   \n",
       "max                              1.000000             1.000000      1.000000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing   roof_Other  \\\n",
       "count               1490.000000   1490.000000  1490.000000   \n",
       "mean                   0.643624      0.189262     0.060403   \n",
       "std                    0.479089      0.391848     0.238311   \n",
       "min                    0.000000      0.000000     0.000000   \n",
       "25%                    0.000000      0.000000     0.000000   \n",
       "50%                    1.000000      0.000000     0.000000   \n",
       "75%                    1.000000      0.000000     0.000000   \n",
       "max                    1.000000      1.000000     1.000000   \n",
       "\n",
       "       roof_Shake Shingle  property_type_Apartment / Condo / Townhouse  \\\n",
       "count         1490.000000                                  1490.000000   \n",
       "mean             0.033557                                     0.419463   \n",
       "std              0.180146                                     0.493637   \n",
       "min              0.000000                                     0.000000   \n",
       "25%              0.000000                                     0.000000   \n",
       "50%              0.000000                                     0.000000   \n",
       "75%              0.000000                                     1.000000   \n",
       "max              1.000000                                     1.000000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                  1490.000000  \n",
       "mean                      0.580537  \n",
       "std                       0.493637  \n",
       "min                       0.000000  \n",
       "25%                       0.000000  \n",
       "50%                       1.000000  \n",
       "75%                       1.000000  \n",
       "max                       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X_train\n",
    "X_train_new = (X_train - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.902281e-16</td>\n",
       "      <td>-4.254613e-17</td>\n",
       "      <td>7.663519e-17</td>\n",
       "      <td>3.911860e-17</td>\n",
       "      <td>9.746119e-17</td>\n",
       "      <td>1.409760e-16</td>\n",
       "      <td>1.621373e-16</td>\n",
       "      <td>2.827995e-16</td>\n",
       "      <td>8.946050e-18</td>\n",
       "      <td>2.315448e-17</td>\n",
       "      <td>-2.132895e-16</td>\n",
       "      <td>1.022299e-16</td>\n",
       "      <td>2.151243e-16</td>\n",
       "      <td>-3.534831e-16</td>\n",
       "      <td>-1.768906e-16</td>\n",
       "      <td>-5.603273e-17</td>\n",
       "      <td>8.032352e-17</td>\n",
       "      <td>-1.070732e-16</td>\n",
       "      <td>1.852359e-16</td>\n",
       "      <td>9.239440e-18</td>\n",
       "      <td>-1.969342e-16</td>\n",
       "      <td>-3.012132e-17</td>\n",
       "      <td>-7.004092e-18</td>\n",
       "      <td>-2.877266e-16</td>\n",
       "      <td>1.457447e-16</td>\n",
       "      <td>1.207088e-17</td>\n",
       "      <td>4.798548e-17</td>\n",
       "      <td>1.039437e-16</td>\n",
       "      <td>2.615358e-17</td>\n",
       "      <td>1.184362e-16</td>\n",
       "      <td>1.359092e-16</td>\n",
       "      <td>-2.747988e-16</td>\n",
       "      <td>-8.278240e-17</td>\n",
       "      <td>-2.752459e-16</td>\n",
       "      <td>2.772577e-16</td>\n",
       "      <td>-2.613867e-16</td>\n",
       "      <td>7.708226e-17</td>\n",
       "      <td>8.941393e-17</td>\n",
       "      <td>-8.941393e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.268801e+00</td>\n",
       "      <td>-1.697190e+00</td>\n",
       "      <td>-1.405276e+00</td>\n",
       "      <td>-3.662250e-01</td>\n",
       "      <td>-2.688343e+00</td>\n",
       "      <td>-8.405927e-01</td>\n",
       "      <td>-9.756023e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-7.559221e-01</td>\n",
       "      <td>-7.162235e-01</td>\n",
       "      <td>-8.905685e-01</td>\n",
       "      <td>-8.761722e-01</td>\n",
       "      <td>-2.495566e+00</td>\n",
       "      <td>-2.943413e+00</td>\n",
       "      <td>-3.511049e+00</td>\n",
       "      <td>-1.655736e+00</td>\n",
       "      <td>-1.532774e+00</td>\n",
       "      <td>-2.789591e+00</td>\n",
       "      <td>-3.439819e+00</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-1.147796e+00</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-2.315581e+00</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>-1.176040e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.047185e-01</td>\n",
       "      <td>-6.224713e-01</td>\n",
       "      <td>-7.491974e-01</td>\n",
       "      <td>-3.219217e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-7.128947e-01</td>\n",
       "      <td>-7.532980e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-6.412758e-01</td>\n",
       "      <td>-7.162235e-01</td>\n",
       "      <td>-7.350745e-01</td>\n",
       "      <td>-6.539411e-01</td>\n",
       "      <td>-8.327346e-01</td>\n",
       "      <td>-5.271130e-01</td>\n",
       "      <td>-6.881804e-01</td>\n",
       "      <td>-6.304329e-01</td>\n",
       "      <td>-6.378058e-01</td>\n",
       "      <td>-7.645042e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-8.648971e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-9.206779e-01</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>-1.176040e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>-3.155383e-01</td>\n",
       "      <td>-1.885809e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-3.936498e-01</td>\n",
       "      <td>-3.086896e-01</td>\n",
       "      <td>-3.559228e-01</td>\n",
       "      <td>-2.936977e-01</td>\n",
       "      <td>-3.737676e-01</td>\n",
       "      <td>-2.901213e-01</td>\n",
       "      <td>-3.074659e-01</td>\n",
       "      <td>-3.205944e-01</td>\n",
       "      <td>-7.690215e-02</td>\n",
       "      <td>2.279809e-01</td>\n",
       "      <td>5.775901e-02</td>\n",
       "      <td>-1.683864e-01</td>\n",
       "      <td>-2.043054e-01</td>\n",
       "      <td>2.480391e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-2.048007e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>9.257749e-03</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-8.497402e-01</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>5.334699e-01</td>\n",
       "      <td>-2.831904e-02</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>3.512552e-01</td>\n",
       "      <td>5.805274e-01</td>\n",
       "      <td>1.178989e-01</td>\n",
       "      <td>1.093814e-01</td>\n",
       "      <td>1.994641e-01</td>\n",
       "      <td>3.490321e-01</td>\n",
       "      <td>4.700041e-01</td>\n",
       "      <td>2.905410e-01</td>\n",
       "      <td>6.789303e-01</td>\n",
       "      <td>7.313768e-01</td>\n",
       "      <td>7.598196e-01</td>\n",
       "      <td>4.740784e-01</td>\n",
       "      <td>4.109853e-01</td>\n",
       "      <td>7.543108e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>6.438946e-01</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>9.391934e-01</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>1.176040e+00</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459364e+00</td>\n",
       "      <td>3.676403e+00</td>\n",
       "      <td>4.255036e+00</td>\n",
       "      <td>1.217405e+01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>4.820685e+00</td>\n",
       "      <td>4.359699e+00</td>\n",
       "      <td>5.685304e+00</td>\n",
       "      <td>5.618130e+00</td>\n",
       "      <td>5.740705e+00</td>\n",
       "      <td>6.740566e+00</td>\n",
       "      <td>5.990042e+00</td>\n",
       "      <td>4.346258e+00</td>\n",
       "      <td>4.609259e+00</td>\n",
       "      <td>1.536810e+00</td>\n",
       "      <td>2.046931e+00</td>\n",
       "      <td>1.779422e+01</td>\n",
       "      <td>1.726156e+01</td>\n",
       "      <td>1.766854e+00</td>\n",
       "      <td>2.360253e+00</td>\n",
       "      <td>3.128982e+00</td>\n",
       "      <td>4.227275e+00</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>1.869129e+00</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>6.353092e+00</td>\n",
       "      <td>3.990129e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>2.714008e+00</td>\n",
       "      <td>5.058652e+00</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>3.558261e+00</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>2.069013e+00</td>\n",
       "      <td>3.942729e+00</td>\n",
       "      <td>5.364762e+00</td>\n",
       "      <td>1.176040e+00</td>\n",
       "      <td>8.497402e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               beds         baths          sqft      lot_size      basement  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean  -1.902281e-16 -4.254613e-17  7.663519e-17  3.911860e-17  9.746119e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.268801e+00 -1.697190e+00 -1.405276e+00 -3.662250e-01 -2.688343e+00   \n",
       "25%   -4.047185e-01 -6.224713e-01 -7.491974e-01 -3.219217e-01  3.717266e-01   \n",
       "50%    5.273226e-01  4.522474e-01 -3.155383e-01 -1.885809e-01  3.717266e-01   \n",
       "75%    5.273226e-01  4.522474e-01  5.334699e-01 -2.831904e-02  3.717266e-01   \n",
       "max    1.459364e+00  3.676403e+00  4.255036e+00  1.217405e+01  3.717266e-01   \n",
       "\n",
       "        restaurants     groceries     nightlife         cafes      shopping  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean   1.409760e-16  1.621373e-16  2.827995e-16  8.946050e-18  2.315448e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -8.405927e-01 -9.756023e-01 -5.928336e-01 -6.967768e-01 -7.559221e-01   \n",
       "25%   -7.128947e-01 -7.532980e-01 -5.928336e-01 -6.967768e-01 -6.412758e-01   \n",
       "50%   -3.936498e-01 -3.086896e-01 -3.559228e-01 -2.936977e-01 -3.737676e-01   \n",
       "75%    3.512552e-01  5.805274e-01  1.178989e-01  1.093814e-01  1.994641e-01   \n",
       "max    4.820685e+00  4.359699e+00  5.685304e+00  5.618130e+00  5.740705e+00   \n",
       "\n",
       "       arts_entertainment   beauty_spas   active_life    median_age  \\\n",
       "count        1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean        -2.132895e-16  1.022299e-16  2.151243e-16 -3.534831e-16   \n",
       "std          1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min         -7.162235e-01 -8.905685e-01 -8.761722e-01 -2.495566e+00   \n",
       "25%         -7.162235e-01 -7.350745e-01 -6.539411e-01 -8.327346e-01   \n",
       "50%         -2.901213e-01 -3.074659e-01 -3.205944e-01 -7.690215e-02   \n",
       "75%          3.490321e-01  4.700041e-01  2.905410e-01  6.789303e-01   \n",
       "max          6.740566e+00  5.990042e+00  4.346258e+00  4.609259e+00   \n",
       "\n",
       "            married  college_grad  property_tax     insurance  median_school  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   1.490000e+03   \n",
       "mean  -1.768906e-16 -5.603273e-17  8.032352e-17 -1.070732e-16   1.852359e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00   \n",
       "min   -2.943413e+00 -3.511049e+00 -1.655736e+00 -1.532774e+00  -2.789591e+00   \n",
       "25%   -5.271130e-01 -6.881804e-01 -6.304329e-01 -6.378058e-01  -7.645042e-01   \n",
       "50%    2.279809e-01  5.775901e-02 -1.683864e-01 -2.043054e-01   2.480391e-01   \n",
       "75%    7.313768e-01  7.598196e-01  4.740784e-01  4.109853e-01   7.543108e-01   \n",
       "max    1.536810e+00  2.046931e+00  1.779422e+01  1.726156e+01   1.766854e+00   \n",
       "\n",
       "        num_schools   two_and_two  property_age  during_recession  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03      1.490000e+03   \n",
       "mean   9.239440e-18 -1.969342e-16 -3.012132e-17     -7.004092e-18   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00      1.000000e+00   \n",
       "min   -3.439819e+00 -3.193783e-01 -1.147796e+00     -6.014412e-01   \n",
       "25%    4.268957e-01 -3.193783e-01 -8.648971e-01     -6.014412e-01   \n",
       "50%    4.268957e-01 -3.193783e-01 -2.048007e-01     -6.014412e-01   \n",
       "75%    4.268957e-01 -3.193783e-01  6.438946e-01      1.661557e+00   \n",
       "max    2.360253e+00  3.128982e+00  4.227275e+00      1.661557e+00   \n",
       "\n",
       "       school_score  exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "count  1.490000e+03          1.490000e+03                 1.490000e+03   \n",
       "mean  -2.877266e-16          1.457447e-16                 1.207088e-17   \n",
       "std    1.000000e+00          1.000000e+00                 1.000000e+00   \n",
       "min   -2.315581e+00         -7.493115e-01                -1.572980e-01   \n",
       "25%   -9.206779e-01         -7.493115e-01                -1.572980e-01   \n",
       "50%    9.257749e-03         -7.493115e-01                -1.572980e-01   \n",
       "75%    9.391934e-01          1.333663e+00                -1.572980e-01   \n",
       "max    1.869129e+00          1.333663e+00                 6.353092e+00   \n",
       "\n",
       "       exterior_walls_Combination  exterior_walls_Metal  \\\n",
       "count                1.490000e+03          1.490000e+03   \n",
       "mean                 4.798548e-17          1.039437e-16   \n",
       "std                  1.000000e+00          1.000000e+00   \n",
       "min                 -2.504503e-01         -2.652453e-01   \n",
       "25%                 -2.504503e-01         -2.652453e-01   \n",
       "50%                 -2.504503e-01         -2.652453e-01   \n",
       "75%                 -2.504503e-01         -2.652453e-01   \n",
       "max                  3.990129e+00          3.767565e+00   \n",
       "\n",
       "       exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count            1.490000e+03          1.490000e+03   \n",
       "mean             2.615358e-17          1.184362e-16   \n",
       "std              1.000000e+00          1.000000e+00   \n",
       "min             -3.682115e-01         -1.975485e-01   \n",
       "25%             -3.682115e-01         -1.975485e-01   \n",
       "50%             -3.682115e-01         -1.975485e-01   \n",
       "75%             -3.682115e-01         -1.975485e-01   \n",
       "max              2.714008e+00          5.058652e+00   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                        1.490000e+03         1.490000e+03  1.490000e+03   \n",
       "mean                         1.359092e-16        -2.747988e-16 -8.278240e-17   \n",
       "std                          1.000000e+00         1.000000e+00  1.000000e+00   \n",
       "min                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "25%                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "50%                         -6.055792e-01        -2.652453e-01 -2.808475e-01   \n",
       "75%                          1.650203e+00        -2.652453e-01 -2.808475e-01   \n",
       "max                          1.650203e+00         3.767565e+00  3.558261e+00   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing    roof_Other  \\\n",
       "count              1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean              -2.752459e-16  2.772577e-16 -2.613867e-16   \n",
       "std                1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min               -1.343434e+00 -4.829980e-01 -2.534612e-01   \n",
       "25%               -1.343434e+00 -4.829980e-01 -2.534612e-01   \n",
       "50%                7.438617e-01 -4.829980e-01 -2.534612e-01   \n",
       "75%                7.438617e-01 -4.829980e-01 -2.534612e-01   \n",
       "max                7.438617e-01  2.069013e+00  3.942729e+00   \n",
       "\n",
       "       roof_Shake Shingle  property_type_Apartment / Condo / Townhouse  \\\n",
       "count        1.490000e+03                                 1.490000e+03   \n",
       "mean         7.708226e-17                                 8.941393e-17   \n",
       "std          1.000000e+00                                 1.000000e+00   \n",
       "min         -1.862765e-01                                -8.497402e-01   \n",
       "25%         -1.862765e-01                                -8.497402e-01   \n",
       "50%         -1.862765e-01                                -8.497402e-01   \n",
       "75%         -1.862765e-01                                 1.176040e+00   \n",
       "max          5.364762e+00                                 1.176040e+00   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                 1.490000e+03  \n",
       "mean                 -8.941393e-17  \n",
       "std                   1.000000e+00  \n",
       "min                  -1.176040e+00  \n",
       "25%                  -1.176040e+00  \n",
       "50%                   8.497402e-01  \n",
       "75%                   8.497402e-01  \n",
       "max                   8.497402e-01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>4.227</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000     0.000     0.000        0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       0.000    0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000      1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000        -0.000   \n",
       "std        1.000          1.000        1.000        1.000         1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.638         -0.765        0.427       -0.319        -0.865   \n",
       "50%       -0.204          0.248        0.427       -0.319        -0.205   \n",
       "75%        0.411          0.754        0.427       -0.319         0.644   \n",
       "max       17.262          1.767        2.360        3.129         4.227   \n",
       "\n",
       "       during_recession  school_score  exterior_walls_Brick  \\\n",
       "count          1490.000      1490.000              1490.000   \n",
       "mean             -0.000        -0.000                 0.000   \n",
       "std               1.000         1.000                 1.000   \n",
       "min              -0.601        -2.316                -0.749   \n",
       "25%              -0.601        -0.921                -0.749   \n",
       "50%              -0.601         0.009                -0.749   \n",
       "75%               1.662         0.939                 1.334   \n",
       "max               1.662         1.869                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.000                   0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.000               -0.000        -0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                     -0.000         0.000      -0.000               0.000   \n",
       "std                       1.000         1.000       1.000               1.000   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                        -0.000  \n",
       "std                          1.000  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train_new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRONG WAY!\n",
    "# X_test_new = (X_test - X_test.mean()) / X_test.std()\n",
    "\n",
    "# Correct way!\n",
    "X_test_new = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count    373.000        373.000      373.000      373.000       373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050         0.013   \n",
       "std        0.908          1.043        0.895        1.068         0.972   \n",
       "min       -1.295         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.666         -0.765        0.427       -0.319        -0.912   \n",
       "50%       -0.246          0.248        0.427       -0.319        -0.158   \n",
       "75%        0.271          0.754        0.427       -0.319         0.691   \n",
       "max        5.375          1.767        2.360        3.129         3.284   \n",
       "\n",
       "       during_recession  school_score  exterior_walls_Brick  \\\n",
       "count           373.000       373.000               373.000   \n",
       "mean             -0.025         0.033                 0.066   \n",
       "std               0.987         1.011                 1.018   \n",
       "min              -0.601        -2.316                -0.749   \n",
       "25%              -0.601        -0.921                -0.749   \n",
       "50%              -0.601         0.009                -0.749   \n",
       "75%               1.662         0.939                 1.334   \n",
       "max               1.662         1.869                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count               373.000                 373.000               373.000   \n",
       "mean                 -0.027                  -0.005                -0.043   \n",
       "std                   0.951                   0.996                 0.890   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                               -0.025               -0.006        -0.003   \n",
       "std                                 0.988                0.991         0.996   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                   373.000       373.000     373.000             373.000   \n",
       "mean                      0.011        -0.004       0.028              -0.052   \n",
       "std                       0.998         0.998       1.051               0.853   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                        -0.112  \n",
       "std                          1.013  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline with Standardization and Lasso Regression\n",
    "make_pipeline(StandardScaler(), Lasso(random_state = 123))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipelines dictionary\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state = 123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state = 123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pipeline for Elastic-Net\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state = 123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=123,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=123,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tuneable hyperparameters of our Lasso pipeline\n",
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = {\n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# Ridge hyperparamters\n",
    "ridge_hyperparameters = {\n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net hyperparameters\n",
    "enet_hyperparameters = {\n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore ConvergenceWarning messages\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and tune model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge has been fitted.\n",
      "enet has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name]\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275110508401\n",
      "ridge 0.3166111585985649\n",
      "enet 0.34287462866116075\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display fitted random forest object\n",
    "fitted_models['lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "# Predict test set using fitted random forest\n",
    "pred = fitted_models['lasso'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.40888624762816383\n",
      "MAE: 85035.54256465769\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R^2 and MAE\n",
    "print('R^2:', r2_score(y_test, pred))\n",
    "print('MAE:', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 observations in the training set.\n",
      "373 observations in the test set.\n"
     ]
    }
   ],
   "source": [
    "print('{} observations in the training set.'.format(len(X_train)))\n",
    "print('{} observations in the test set.'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=123, solver='auto', tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "# Pipeline object of our Ridge pipeline\n",
    "print(pipelines['ridge'])lasso_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.3, 0.5, 0.7, 0.9]\n"
     ]
    }
   ],
   "source": [
    "print(enet_hyperparameters['elasticnet__l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.434228187919463\n",
      "Standard Deviation: 1.0729140858452646\n"
     ]
    }
   ],
   "source": [
    "print('Mean:', X_train.beds.mean())\n",
    "print('Standard Deviation:', X_train.beds.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689    1.799\n",
       "1531    0.799\n",
       "668    -0.201\n",
       "1740    1.799\n",
       "117    -1.201\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.beds.head() - 3.434228187919463 / 1.0729140858452646 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266   -1.201\n",
       "790   -0.201\n",
       "222   -1.201\n",
       "220   -1.201\n",
       "920   -0.201\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.beds.head() - 3.434228187919463 / 1.0729140858452646 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.434228187919463\n",
      "Standard Deviation: 1.0725539871320342\n"
     ]
    }
   ],
   "source": [
    "print('Mean:', scaler.mean_[0])\n",
    "print('Standard Deviation:', scaler.scale_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test_new = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(373, 39)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_test_new))\n",
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_new[:5,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pipeline for rf and gb\n",
    "# Pipeline with Standardization and RandomForestRegressor Tree Ensemble\n",
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state = 123))\n",
    "# Pipeline with Standardization and GradientBoostingRegressor\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state = 123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "  ...rs='warn', n_jobs=None,\n",
      "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(pipelines['rf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pipelines['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have all 5 model families, and that they are all pipelines\n",
    "for key, value in pipelines.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tuneable hyperparameters of our rf pipeline\n",
    "# pipelines['rf'].get_params()\n",
    "\n",
    "# RandomForestRegressor hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators' : [100, 200],\n",
    "    'randomforestregressor__max_features' : ['auto','sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tuneable hyperparameters of our gb pipeline\n",
    "# pipelines['gb'].get_params()\n",
    "\n",
    "# GradientBoostingRegressor hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators' : [100, 200],\n",
    "    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1, 3, 5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name]\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have all 5 model families, and that they are all fitted_models\n",
    "for key, value in fitted_models.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275110508401\n",
      "ridge 0.3166111585985649\n",
      "enet 0.34287462866116075\n",
      "rf 0.48052493948124625\n",
      "gb 0.4878281491449502\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "--------\n",
      "R^2: 0.40888624762816383\n",
      "MAE: 85035.54256465769\n",
      "\n",
      "ridge\n",
      "--------\n",
      "R^2: 0.4093396476329718\n",
      "MAE: 84978.03564808934\n",
      "\n",
      "enet\n",
      "--------\n",
      "R^2: 0.40524513731263\n",
      "MAE: 86298.63725254669\n",
      "\n",
      "rf\n",
      "--------\n",
      "R^2: 0.5710019128514657\n",
      "MAE: 67900.87068364612\n",
      "\n",
      "gb\n",
      "--------\n",
      "R^2: 0.5271611798572793\n",
      "MAE: 71153.96848408955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print('--------')\n",
    "    print('R^2:', r2_score(y_test, pred))\n",
    "    print('MAE:', mean_absolute_error(y_test, pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshua.kemp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_pred = fitted_models['rf'].predict(X_test)\n",
    "plt.scatter(rf_pred, y_test)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
